license()
q()
library(readr)
library(dplyr)
library(DMwR)
library(nnet)
#Dataset link: https://www.kaggle.com/buntyshah/auto-insurance-claims-data
# dataset = read.csv( "insurance_claims.csv")
dataset = read.csv("enron.csv")
setwd("~/GitHub/COMP7410/Assignment2")
library(readr)
library(dplyr)
library(DMwR)
library(nnet)
#Dataset link: https://www.kaggle.com/buntyshah/auto-insurance-claims-data
# dataset = read.csv( "insurance_claims.csv")
dataset = read.csv("enron.csv")
dataset = dataset[,c(-1,-8)] # delete variables
dataset = dataset %>% mutate_if(is.character,as.factor)
dataset[, -1][is.na(dataset[, -1])] <- 0
dataset <- dataset[!is.nan(dataset$salary), ]
dataset = as.data.frame(dataset)
round(prop.table(table(dataset$poi)),2)
table(dataset$poi)
# dataset$policy_bind_date = as.Date(dataset$policy_bind_date) - as.Date("1990-01-08")
# dataset$incident_date = as.Date(dataset$incident_date) - as.Date("2015-01-01")
newData <- SMOTE(poi ~ ., dataset, perc.over = 400,perc.under=100)
table(newData$poi)
library(randomForest)
library(caret)
dataset_rf = data.frame(newData)
train = sample(nrow(dataset_rf), 0.7*nrow(dataset_rf), replace = FALSE)
TrainSet = dataset_rf[train,]
TestSet = dataset_rf[-train,]
model_rf = randomForest(poi ~ ., data=TrainSet,mtry = 4, ntree=500, importance = TRUE)
model_rf
prediction_rf = predict(model_rf,TestSet)
confusionMatrix(prediction_rf,TestSet$poi)
set.seed(2023)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=400,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
set.seed(2023)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
dataset = read.csv("enron.csv")
dataset = dataset[,c(-1,-8)] # delete variables
dataset = dataset %>% mutate_if(is.character,as.factor)
dataset[, -1][is.na(dataset[, -1])] <- 0
dataset <- dataset[!is.nan(dataset$salary), ]
dataset = as.data.frame(dataset)
round(prop.table(table(dataset$poi)),2)
table(dataset$poi)
dataset = read.csv("enron.csv")
dataset = dataset[,c(-1,-8)] # delete variables
dataset = dataset %>% mutate_if(is.character,as.factor)
# dataset[, -1][is.na(dataset[, -1])] <- 0
dataset <- dataset[!is.nan(dataset$salary), ]
dataset = as.data.frame(dataset)
round(prop.table(table(dataset$poi)),2)
table(dataset$poi)
dataset = read.csv("enron.csv")
View(dataset)
library(readr)
library(dplyr)
library(DMwR)
library(nnet)
#Dataset link: https://www.kaggle.com/buntyshah/auto-insurance-claims-data
# dataset = read.csv( "insurance_claims.csv")
dataset = read.csv("enron.csv")
dataset = dataset[,c(-1,-8)] # delete variables
dataset = dataset %>% mutate_if(is.character,as.factor)
dataset[, -1][is.na(dataset[, -1])] <- 0
dataset <- dataset[!is.nan(dataset$salary), ]
dataset = as.data.frame(dataset)
round(prop.table(table(dataset$poi)),2)
table(dataset$poi)
# dataset$policy_bind_date = as.Date(dataset$policy_bind_date) - as.Date("1990-01-08")
# dataset$incident_date = as.Date(dataset$incident_date) - as.Date("2015-01-01")
newData <- SMOTE(poi ~ ., dataset, perc.over = 400,perc.under=100)
table(newData$poi)
#####################
####Random Forest####
#####################
library(randomForest)
library(caret)
dataset_rf = data.frame(newData)
train = sample(nrow(dataset_rf), 0.7*nrow(dataset_rf), replace = FALSE)
TrainSet = dataset_rf[train,]
TestSet = dataset_rf[-train,]
model_rf = randomForest(poi ~ ., data=TrainSet,mtry = 4, ntree=500, importance = TRUE)
model_rf
prediction_rf = predict(model_rf,TestSet)
confusionMatrix(prediction_rf,TestSet$poi)
#####################
####Neural Network###
#####################
#Calculate the error and find a better model
set.seed(2023)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=500,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=600,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
library(randomForest)
library(caret)
dataset_rf = data.frame(newData)
train = sample(nrow(dataset_rf), 0.7*nrow(dataset_rf), replace = FALSE)
TrainSet = dataset_rf[train,]
TestSet = dataset_rf[-train,]
model_rf = randomForest(poi ~ ., data=TrainSet,mtry = 4, ntree=500, importance = TRUE)
model_rf
prediction_rf = predict(model_rf,TestSet)
confusionMatrix(prediction_rf,TestSet$poi)
#Final model and evaluation result
model_best=nnet(poi ~ ., data=TrainSet,maxit=600,size=19,decay = 0.1)
prediction_test = predict(model_best,TestSet,type="class")
table = table(TestSet$poi,prediction_test)
confusionMatrix(table)
set.seed(2023)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
set.seed(2023)
err11=0
err12=0
n_tr=dim(TrainSet)[1]
n_te=dim(TestSet)[1]
for(i in seq(1, 601, 100))
{
model=nnet(poi ~ ., data=TrainSet,maxit=i,size=19,decay = 0.1)
err11[i]=sum(predict(model,TrainSet,type='class')!=TrainSet[,16])/n_tr
err12[i]=sum(predict(model,TestSet,type='class')!=TestSet[,16])/n_te
}
error_1 = na.omit(err11)
error_2 = na.omit(err12)
plot(seq(1, 601, 100),error_1,col=1,type="b",ylab="Error rate",xlab="Training epoch",ylim=c(min(min(error_1),min(error_2)),max(max(error_1),max(error_2))))
lines(seq(1, 601, 100),error_2,col=2,type="b")
legend("topleft",pch=c(15,15),legend=c("Train","Test"),col=c(1,2),bty="n")
